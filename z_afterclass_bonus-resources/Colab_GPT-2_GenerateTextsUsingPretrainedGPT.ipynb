{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trying GPT-2 playground.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "gaI4yHpg_r6K"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI-HVDbQS9dF",
        "colab_type": "text"
      },
      "source": [
        "# GPT-2 Playground\n",
        "\n",
        "## Background\n",
        "**Open AI's GPT-2** Language Model from the paper **[Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)**. You'll be able to choose between the small (**117M** parameters) , medium (**345M** parameters), large (**774M** parameters) and XL versions (**1.5B** parameters) version of GPT-2.  \n",
        "\n",
        "*(original playground here: https://colab.research.google.com/github/ilopezfr/gpt-2/blob/master/gpt-2-playground_.ipynb )*\n",
        "\n",
        "\n",
        "\n",
        "----\n",
        "\n",
        "\n",
        "## Steps\n",
        "Before starting, is recommended to set *Runtime Type* to *GPU* on the top menu bar.\n",
        "\n",
        "\n",
        "###1. Installation\n",
        "Clone the repo, install dependencies, and download the model weights. \n",
        "\n",
        "You can choose between the small 117M, medium 345M, large 774M model, xl 1.5B model or all of them.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKqlSCrpS9dH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ace020fd-ee47-415e-d422-d14c60e6ba22"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "!git clone https://github.com/ilopezfr/gpt-2/\n",
        "import os\n",
        "os.chdir('gpt-2')\n",
        "# !python download_model.py 117M\n",
        "!python download_model.py 345M\n",
        "!python download_model.py 774M\n",
        "# !python download_model.py 1558M\n",
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Cloning into 'gpt-2'...\n",
            "remote: Enumerating objects: 310, done.\u001b[K\n",
            "remote: Total 310 (delta 0), reused 0 (delta 0), pack-reused 310\u001b[K\n",
            "Receiving objects: 100% (310/310), 4.63 MiB | 6.78 MiB/s, done.\n",
            "Resolving deltas: 100% (174/174), done.\n",
            "Fetching checkpoint: 1.00kit [00:00, 1.18Mit/s]                                                     \n",
            "Fetching encoder.json: 1.04Mit [00:00, 45.4Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 846kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:22, 63.4Mit/s]                                 \n",
            "Fetching model.ckpt.index: 11.0kit [00:00, 10.8Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 927kit [00:00, 55.1Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 54.4Mit/s]                                                       \n",
            "Fetching checkpoint: 1.00kit [00:00, 1.24Mit/s]                                                     \n",
            "Fetching encoder.json: 1.04Mit [00:00, 54.5Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 1.37Mit/s]                                                   \n",
            "Fetching model.ckpt.data-00000-of-00001: 3.10Git [01:01, 50.3Mit/s]                                 \n",
            "Fetching model.ckpt.index: 16.0kit [00:00, 13.2Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 1.38Mit [00:00, 66.1Mit/s]                                                \n",
            "Fetching vocab.bpe: 457kit [00:00, 63.5Mit/s]                                                       \n",
            "Collecting fire>=0.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/a7/0e22e70778aca01a52b9c899d9c145c6396d7b613719cd63db97ffa13f2f/fire-0.3.1.tar.gz (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 5.7MB/s \n",
            "\u001b[?25hCollecting regex==2018.1.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/f4/7146c3812f96fcaaf2d06ff6862582302626a59011ccb6f2833bb38d80f7/regex-2018.01.10.tar.gz (612kB)\n",
            "\u001b[K     |████████████████████████████████| 614kB 22.1MB/s \n",
            "\u001b[?25hCollecting requests==2.21.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.2MB/s \n",
            "\u001b[?25hCollecting tqdm==4.31.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.1.0)\n",
            "Collecting idna<2.9,>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2020.6.20)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Building wheels for collected packages: fire, regex\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.3.1-py2.py3-none-any.whl size=111005 sha256=99511152e905084cded91ae3ef69a323f7bff5610a43dfa596ecbe18afe7d970\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/61/df/768b03527bf006b546dce284eb4249b185669e65afc5fbb2ac\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2018.1.10-cp36-cp36m-linux_x86_64.whl size=548009 sha256=231325ae94a6a73182dfd9e3a4f21e2fc2c834db41a77e94ac04f5940bc5ac05\n",
            "  Stored in directory: /root/.cache/pip/wheels/74/17/3f/c77bba99efd74ba1a19862c9dd97f4b6d735e2826721dc00ff\n",
            "Successfully built fire regex\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.31.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.21.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: fire, regex, idna, requests, tqdm\n",
            "  Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Found existing installation: idna 2.9\n",
            "    Uninstalling idna-2.9:\n",
            "      Successfully uninstalled idna-2.9\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed fire-0.3.1 idna-2.8 regex-2018.1.10 requests-2.21.0 tqdm-4.31.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "idna",
                  "requests",
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCH2tCx__of2",
        "colab_type": "text"
      },
      "source": [
        "## 1. Text Completion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaI4yHpg_r6K",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Sample Prompts:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xfskdff44QlD",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Sample prompt 1: \n",
        "```\n",
        "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
        "```\n",
        "\n",
        "Sample prompt 2: ([*Voight-Kampff test*](https://www.youtube.com/watch?v=Umc9ezAyJv0))\n",
        "\n",
        "```\n",
        "You're in a desert, walking along in the sand, when all of a sudden you look down and see a tortoise, Leon. It's crawling toward you. You reach down, you flip the tortoise over on its back. The tortoise lays on its back, its belly baking in the hot sun, beating its legs trying to turn itself over, but it can’t, not without your help. But you’re not helping. Why is that? \n",
        "```\n",
        "\n",
        "Sample prompt 3:\n",
        "```\n",
        "I've seen things you people wouldn't believe. Attack ships on fire off the shoulder of Orion. I watched C-beams glitter in the dark near the Tannhäuser Gate. All those moments will be lost in time, like tears in rain. Time to die.\n",
        "```\n",
        "\n",
        "Sample prompt 4:\n",
        "```\n",
        "Outfit 1: Typical This pairing was the first outfit I thought of when I bought the shoes. It’s like a summer version of this Jake Grantham outfit; in fact, my shoes are close to the colors of his Nike Racers! Instead of a heavy Harris Tweed jacket and denim shirt, I’m wearing a cotton DB jacket and and a linen shirt. Both fabrics (in these colors) are an absolute must for summer, as they go with both dark and and light pants! As you can see, they pair wonderfully with the dark jeans and shoes. It’s a pseudo menswear/prep outfit. Overall, this is a very casual outfit which is why I paired my sneakers with it. I’m not about wearing a full wool suit with sneakers (as GQ shows a lot) but I’m definitely open to keeping things casual, like this cotton DB. Casual fabrics are key to pulling off your sneakers in a dressed down menswear outfit. I’d even suggest to wear these sneakers with a khaki chino suit or a white linen suit. Just be sure to ditch the tie or wear a tee or polo; wearing a tie with sneakers is a bit too much \n",
        "```\n",
        "Sample prompt 5:\n",
        "```\n",
        "- Some of the most glorious historical attractions in Spain date from the period of Muslim rule, including The Mezquita, built as the Great Mosque of Cordoba and the Medina Azahara, also in Cordoba, the Palace of al-Andalus; and the Alhambra in Granada, a splendid, intact palace.\n",
        "```\n",
        "Sample prompt 6:\n",
        "```\n",
        "How can Artificial Intelligence be dangerous? Most researchers agree that a superintelligent AI is unlikely to exhibit human emotions like love or hate, and that there is no reason to expect AI to become intentionally benevolent or malevolent. Instead, when considering how AI might become a risk, experts think two scenarios most likely:\n",
        "```\n",
        "Sample prompt 7:\n",
        "```\n",
        "Our solar system consists of the inner and outer planets, separated by an asteroid belt. It has \n",
        "```\n",
        "Sample prompt 8:\n",
        "```\n",
        "The 10 best foods are: 1. Serrano Ham 2. Manchego Cheese 3.  \n",
        "```\n",
        "Sample prompt 9:\n",
        "```\n",
        "Real Madrid boss Santiago Solari admitted his team put in a 'weak performance' in their 1-0 Copa del Rey loss to local rivals Leganes. Despite losing the game, Los Blancos will progress to the quarter final stages of the tournament, winning the tie 3-1 on aggregate thanks to a 3-0 victory in the first leg. \"It was a difficult game, but the performance was weak,\" Real Madrid boss Santi Solari on the\n",
        "```\n",
        "Sample prompt 10:\n",
        "```\n",
        "Roses are read, violets are blue,\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFQB0VlUGvk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiI5v470_uzP",
        "colab_type": "text"
      },
      "source": [
        "### The code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QIdaQn5WkSf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1c7c1fb1-030a-4314-e677-ce32d203e1cb"
      },
      "source": [
        "!python3 src/interactive_conditional_samples.py --model_name='774M' --nsamples=2 --top_k=40 --temperature=.80"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:57: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-07-12 12:28:14.623302: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-07-12 12:28:14.690291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-12 12:28:14.690863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-12 12:28:14.691186: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-12 12:28:14.946986: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-12 12:28:15.069144: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-12 12:28:15.102517: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-12 12:28:15.359765: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-12 12:28:15.401535: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-12 12:28:15.881558: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-12 12:28:15.881764: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-12 12:28:15.882435: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-12 12:28:15.882939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-12 12:28:15.883434: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
            "2020-07-12 12:28:15.904655: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000129999 Hz\n",
            "2020-07-12 12:28:15.905005: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2f63100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-12 12:28:15.905035: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-07-12 12:28:16.048872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-12 12:28:16.049590: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2f632c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-12 12:28:16.049625: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-07-12 12:28:16.050811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-12 12:28:16.051367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-12 12:28:16.051445: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-12 12:28:16.051473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-12 12:28:16.051497: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-12 12:28:16.051520: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-12 12:28:16.051542: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-12 12:28:16.051564: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-12 12:28:16.051588: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-12 12:28:16.051666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-12 12:28:16.052223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-12 12:28:16.052721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-12 12:28:16.055030: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-12 12:28:16.056738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-12 12:28:16.056772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-07-12 12:28:16.056785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-07-12 12:28:16.057870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-12 12:28:16.058512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-12 12:28:16.059095: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-07-12 12:28:16.059146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:58: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:60: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:51: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:64: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:16: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:67: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:68: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "Model prompt >>> Hello everyone, Welcome to the Exploring Machine Intelligence class where we study about deep learning for artists. Today's topic is \n",
            "2020-07-12 12:28:58.845781: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "======================================== SAMPLE 1 ========================================\n",
            " what is an Artist?  I've been looking into this a lot and found that artists tend to be more similar than most other people.  Most people have a hard time defining an artist, especially if they don't know the artist very well, but it seems that artists tend to be very similar.  It's not unusual for artists to be friends, like people in different countries, or to be musicians or graphic designers.  Even if there are not many similarities, this is what I'm going to attempt to describe.  A musician is like a painter or a designer.  They make a connection between themselves and the world and create a unique voice.  They are a unique voice.  They take an art form that most people don't have the opportunity to do and make it their own.  They want to write their own new music.  They want to create their own sound.  They want to experiment with sounds and sounds they don't normally use in their work.  They are a unique voice.  They have personality.  They need space and time to create and record.  They are very passionate about their art and want to communicate it through music.  They have a passion for their work and want people to share that with others.  They are a unique voice.  They are a unique personality. A graphic designer is like a painter, but using graphics instead of words.  They take an art form that most people don't have the opportunity to do and make it their own.  They are a unique voice.  They want to communicate with their audience through design.  They are a unique personality. A musician is like a painter, but using music instead of words.  They take an art form that most people don't have the opportunity to do and make it their own.  They are a unique voice.  They want to communicate with their audience through music.  They are a unique personality. A graphic designer is like a painter, but using music instead of words.  They take an art form that most people don't have the opportunity to do and make it their own.  They are a unique voice.  They want to communicate with their audience through design.  They are a unique personality. When we talk about artists and their personalities, I'm talking about the way they communicate with their audience.  A lot of this\n",
            "======================================== SAMPLE 2 ========================================\n",
            " the use of a deep neural network to make a 3D scene. Today's example is a scene from the movie \" The Lego Movie \". In the movie the 3D scene is based on an image which is a real world building which is based on the idea of Lego bricks. The image is a picture of a building which is just a bunch of bricks. The 3D scene uses a deep neural network to make these bricks into a 3D scene. We are going to use the LSTM architecture which is a type of convolutional neural network.\n",
            "1. Let's start by creating a new Python script called \"LSTM.py\" with the ID:  \"10\"  and the name \"LSTM_TEST.py\".\n",
            "2. You can use the following command to run the script:\n",
            "$ python LSTM_TEST.py\n",
            "In the text file \"LSTM_TEST.py\" you will find the following code which is based on the LSTM architecture:\n",
            "3. We are going to use this code to learn the 3D scene. We will not be using the LSTM architecture in this tutorial. We will use the simple backpropagation method to learn the 3D scene:\n",
            "4. In the text file \"LSTM_TEST.py\" you will find the following code which is based on the simple backpropagation:\n",
            "5. We have created a new file named \"lstm_tests.txt\" with the following lines as the title:\n",
            "6. We are going to use the backpropagation method to build the scene, we are using the following method to train the LSTM:\n",
            "7. In the text file named \"lstm_tests.txt\" you will find the following code which is based on the backpropagation method:\n",
            "8. We have created a new file called \"lstm_tests.h\" with the following lines as the title:\n",
            "9. We are going to use the backpropagation method to build the scene, we are using the following method to train the LSTM:\n",
            "10. In the text file named \"lstm_tests.h\" you will find the following code which is based on the backpropagation method:\n",
            "11. We have created a new file named \"lstm_tests.cpp\" with the following lines as the title:\n",
            "================================================================================\n",
            "Model prompt >>> Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/contextlib.py\", line 99, in __exit__\n",
            "    self.gen.throw(type, value, traceback)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 5480, in get_controller\n",
            "    yield g\n",
            "  File \"src/interactive_conditional_samples.py\", line 73, in interact_model\n",
            "    raw_text = input(\"Model prompt >>> \")\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"src/interactive_conditional_samples.py\", line 91, in <module>\n",
            "    fire.Fire(interact_model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 138, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 468, in _Fire\n",
            "    target=component.__name__)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 672, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"src/interactive_conditional_samples.py\", line 88, in interact_model\n",
            "    print(\"=\" * 80)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1634, in __exit__\n",
            "    close_thread.join(30.0)\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1060, in join\n",
            "    self._wait_for_tstate_lock(timeout=max(timeout, 0))\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1072, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9ABLt12ANRe",
        "colab_type": "text"
      },
      "source": [
        "I tested a prompt with which I usually started our lectures:\n",
        "\n",
        "```\n",
        "Hello everyone, Welcome to the Exploring Machine Intelligence class where we study about deep learning for artists. Today's topic is\n",
        "```\n",
        "\n",
        "... and look at the log for what it continued with (LSTM.py :D)"
      ]
    }
  ]
}